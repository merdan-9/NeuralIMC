defaults:
  - ppo
  - _self_

name: mppi_resrl
algo_name: mppi_resrl # use ppo to train the controller

minimize_residual_err: false
k_pos: 0.5
k_vel: 0.1
k_quat: 0.1
k_raw: 0.0

mppi:
  lam: 0.1 # temparature
  H: 20 # horizon
  N: 4096 # number of samples
  K_delay: 1
  sim_K_delay : 1

  sample_std: [0.25, 0.7, 0.7, 0.7] # standard deviation for sampling: [thrust (unit: hovering thrust), omega (unit: rad/s)]
  gamma_mean: 1.0 # learning rate
  gamma_Sigma: 0. # learning rate
  omega_gain: 40. # gain of the low-level controller
  discount: 0.99 # discount factor in MPPI
  a_min: [0., -5., -5., -2.] # bounds of sampling action: [thrust, omega (unit: rad/s)]
  a_max: [0., 5., 5., 2.]

  # reward functions
  alpha_p: 10.0
  alpha_w: 0.0
  alpha_a: 0.0
  alpha_R: 10.0
  alpha_v: 0.0
  alpha_z : 0.0
  alpha_yaw : 0.0

  pos_noise_std: 0.005
  vel_noise_std: 0.005
  quat_noise_std: 0.01